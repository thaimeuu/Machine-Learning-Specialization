## Feature scaling part 1

**feature scaling** is a technique that makes **gradient descent** run much faster

*Example*

|size (ft<sup>2</sup>)|bedrooms|price (k$)|
|:---:|:---:|:---:|
|300|0|75|
|2000|5|500|

Let's assume we have 2 training examples with 2 features in each example.

- Size: 300-2000 (quite large)
- Bedrooms: 0-5 (quite small)

Let's try out 2 models:

1. f<sub>w,b</sub> = 50x<sub>1</sub>+0.1x<sub>2</sub>+50
2. f<sub>w,b</sub> = 0.1x<sub>1</sub>+50x<sub>2</sub>+50

Let's predict example 2 using 2 models:

1. y-hat = 50\*2000 + 0.1*5 + 50 = 100,050.5 (poor result)
2. y-hat = 0.1\*2000 + 50*5 + 50 = 500 (good result)

**CONCLUSION**

- Feature x<sub>i</sub> with large values should go with relatively small value of w<sub>i</sub>
- A scatter plot of features may be unusable with features of different values' ranges with the same scaling (i.e. q unit of feature 1 == 1 unit of feature 2)
- We need to scale the features' values (e.g. range<sub>1</sub> == range<sub>2</sub> == 1 unit)

![Alt text](<1. img.png>)