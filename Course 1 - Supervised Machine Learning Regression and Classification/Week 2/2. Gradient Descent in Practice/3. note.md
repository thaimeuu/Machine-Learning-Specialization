## Checking gradient descent for convergence

***Question: How to check if gradient descent converges at global minimum instead of local minimum or some values close to global minimum?***

![Alt text](<3. img.png>)

A graph that shows the dependence between cost **J** and **# iterations** should look like this:

- After every iteration, cost should decrease. Else, learning rate may be poorly chosen or there is a bug in your code
- The graph should converge after a number of iterations