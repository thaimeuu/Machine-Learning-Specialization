## `Improved implementation of softmax`

The Softmax code from the [previous note](<3. note.md>) will cause **Numerical Roundoff Errors**. There is another way that is recommended:

![Alt text](<ref img/4.png>)

**from_logits=True** means **the computer will compute z using linear activation (i.e. logits=z)** rather than compute g(z) using Softmax activation which may cause Numerical Roundoff Errors

The model will now predict **logits or z** so we have to feed the prediction into `tf.nn.softmax(logits)` as a final prediction