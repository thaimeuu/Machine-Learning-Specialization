## `Random forest algorithm`

> Now that we have a way to use sampling with replacement to create new training sets that are a bit similar to but also quite different from the original training set. We're ready to build our first tree ensemble algorithm. In particular in this video, we'll talk about the random forest algorithm which is one powerful tree ensemble algorithm that works much better than using a single decision tree.

### `Bagged decision tree`

- The `Bagged decision tree` algorithm contains **B trees/datasets**. Each dataset is created using **sampling with replacement**. B, for example, equals to 100.

![Alt text](<ref img/5.png>)

### `Randomizing the feature choice`

- We can increase the randomization of the ensemble by limiting the choice of features that can be chosen as decision nodes.

![Alt text](<ref img/6.png>)

### `Machine learning jokes`

> Before wrapping up this video there's just one more thought I want to share with you Which is, where does a machine learning engineer go camping? 

> In a random forest. 

![Alt text](<ref img/7.png>)