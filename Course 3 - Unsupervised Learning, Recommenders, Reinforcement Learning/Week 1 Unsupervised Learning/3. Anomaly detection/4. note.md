## `Developing and evaluating an anomaly detection system`

> I'd like to share with you some **practical tips for developing an anomaly detection system**. One of the key ideas will be that if you can have a way to evaluate a system, even as it's being developed, you'll be able to make decisions and change the system and improve it much more quickly.

![Alt text](<ref img/13.png>)

> In practice, anomaly detection algorithm will work okay if there are some examples that are actually anomalous, but there were accidentally labeled with y equals 0.

## `Example`

![Alt text](<ref img/14.png>)

> Let's illustrate this with the aircraft engine example. Let's say you have been manufacturing aircraft engines for years and so you've collected data from **10,000 good or normal engines**, but over the years you had also collected data from **20 flawed or anomalous engines.** Usually the number of anomalous engines, that is y equals 1, will be much smaller. It will not be a typical to apply this type of algorithm with anywhere from, say, 2-50 known anomalies.

![Alt text](<ref img/15.png>)

## `Algorithm evaluation`

![Alt text](<ref img/16.png>)

> Now, this does raise the question, if you have a few labeled examples, since you'll still be using an unsupervised learning algorithm, why not take those labeled examples and use a supervised learning algorithm instead? In the next video, let's take a look at a comparison between anomaly detection and supervised learning and when you might prefer one over the other.